{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Analysis Review: Taylor Swift Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load(\"en\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While driving and listening to the radio, I recently had an encounter with one of Taylor Swift's songs. Her lyrics were easy to understand and it got me thinking about how they compare to the most common words of the English language and how they compare to other artists. \n",
    "This lead me on a journey of parsing and tokenizing to answer the overall question: \n",
    "\n",
    "``` How do Taylor Swift's lyrics compare to the most common words of the English language?```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is free to use from [this website](https://www.kaggle.com/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums). It contains lyrics from 6 of her 7 albums organized by line. Unfortunately her most recent album \"Lover\" was not available at the time of this analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "data = pd.read_csv(\"data/taylor_swift_lyrics.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track_title</th>\n",
       "      <th>track_n</th>\n",
       "      <th>lyric</th>\n",
       "      <th>line</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1</td>\n",
       "      <td>He said the way my blue eyes shined</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1</td>\n",
       "      <td>Put those Georgia stars to shame that night</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1</td>\n",
       "      <td>I said, \"That's a lie\"</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1</td>\n",
       "      <td>Just a boy in a Chevy truck</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1</td>\n",
       "      <td>That had a tendency of gettin' stuck</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist         album track_title  track_n  \\\n",
       "0  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
       "1  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
       "2  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
       "3  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
       "4  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
       "\n",
       "                                         lyric  line  year  \n",
       "0          He said the way my blue eyes shined     1  2006  \n",
       "1  Put those Georgia stars to shame that night     2  2006  \n",
       "2                       I said, \"That's a lie\"     3  2006  \n",
       "3                  Just a boy in a Chevy truck     4  2006  \n",
       "4         That had a tendency of gettin' stuck     5  2006  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset chosen has 7 columns and 4862 rows with the definition of the columns below:\n",
    "\n",
    "* `artist`: Artist name\n",
    "* `album`: Album name\n",
    "* `track_title`: Song title\n",
    "* `track_n`: Track number in the album\n",
    "* `lyric`: Song lyric\n",
    "* `line`: Line number in the song\n",
    "* `year`: the year album was released\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is organized by song line which means I'll need to wrangle the data to concatenate the lyric column by song. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>track_n</th>\n",
       "      <th>track_title</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>Welcome to New York</td>\n",
       "      <td>Walking through a crowd, the village is aglow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>Blank Space</td>\n",
       "      <td>Nice to meet you, where you been? I could show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>Style</td>\n",
       "      <td>Midnight You come and pick me up, no headlight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>Out of the Woods</td>\n",
       "      <td>Looking at it now It all seems so simple We we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>All You Had to Do Was Stay</td>\n",
       "      <td>People like you always want back The love they...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  album  year  track_n                 track_title  \\\n",
       "0  1989  2014        1         Welcome to New York   \n",
       "1  1989  2014        2                 Blank Space   \n",
       "2  1989  2014        3                       Style   \n",
       "3  1989  2014        4            Out of the Woods   \n",
       "4  1989  2014        5  All You Had to Do Was Stay   \n",
       "\n",
       "                                               lyric  \n",
       "0  Walking through a crowd, the village is aglow ...  \n",
       "1  Nice to meet you, where you been? I could show...  \n",
       "2  Midnight You come and pick me up, no headlight...  \n",
       "3  Looking at it now It all seems so simple We we...  \n",
       "4  People like you always want back The love they...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will group by the track title and keep all the needed columns.\n",
    "# The lines are being joined with a simple space\n",
    "data = data.groupby(['album', 'year', 'track_n', 'track_title', ])[\n",
    "    'lyric'].apply(' '.join).reset_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now is grouped by the track title and will be easier to tokenize. Below are some easy summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>track_n</th>\n",
       "      <th>track_title</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>Tall, dark, and superman He puts papers in his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011.329787</td>\n",
       "      <td>8.457447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.557178</td>\n",
       "      <td>4.753414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album         year    track_n track_title  \\\n",
       "count     94    94.000000  94.000000          94   \n",
       "unique     6          NaN        NaN          94   \n",
       "top      Red          NaN        NaN          22   \n",
       "freq      19          NaN        NaN           1   \n",
       "mean     NaN  2011.329787   8.457447         NaN   \n",
       "std      NaN     3.557178   4.753414         NaN   \n",
       "min      NaN  2006.000000   1.000000         NaN   \n",
       "25%      NaN  2008.000000   4.250000         NaN   \n",
       "50%      NaN  2012.000000   8.000000         NaN   \n",
       "75%      NaN  2014.000000  12.000000         NaN   \n",
       "max      NaN  2017.000000  19.000000         NaN   \n",
       "\n",
       "                                                    lyric  \n",
       "count                                                  94  \n",
       "unique                                                 94  \n",
       "top     Tall, dark, and superman He puts papers in his...  \n",
       "freq                                                    1  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to add a word count feature to the data set. I feel this could potentially be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>track_n</th>\n",
       "      <th>track_title</th>\n",
       "      <th>lyric</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>Welcome to New York</td>\n",
       "      <td>Walking through a crowd, the village is aglow ...</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>Blank Space</td>\n",
       "      <td>Nice to meet you, where you been? I could show...</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>Style</td>\n",
       "      <td>Midnight You come and pick me up, no headlight...</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>Out of the Woods</td>\n",
       "      <td>Looking at it now It all seems so simple We we...</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>All You Had to Do Was Stay</td>\n",
       "      <td>People like you always want back The love they...</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  album  year  track_n                 track_title  \\\n",
       "0  1989  2014        1         Welcome to New York   \n",
       "1  1989  2014        2                 Blank Space   \n",
       "2  1989  2014        3                       Style   \n",
       "3  1989  2014        4            Out of the Woods   \n",
       "4  1989  2014        5  All You Had to Do Was Stay   \n",
       "\n",
       "                                               lyric  word_count  \n",
       "0  Walking through a crowd, the village is aglow ...         321  \n",
       "1  Nice to meet you, where you been? I could show...         502  \n",
       "2  Midnight You come and pick me up, no headlight...         371  \n",
       "3  Looking at it now It all seems so simple We we...         652  \n",
       "4  People like you always want back The love they...         453  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word_count'] = data['lyric'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert all the uppercases to lower case lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_lyrics'] = data['lyric'].apply(\n",
    "    lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# And replace hephenated words into clearly defined words \n",
    "data[\"clean_lyrics\"]= data[\"clean_lyrics\"].str.replace(\"-\", \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>track_n</th>\n",
       "      <th>track_title</th>\n",
       "      <th>lyric</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>Welcome to New York</td>\n",
       "      <td>Walking through a crowd, the village is aglow ...</td>\n",
       "      <td>321</td>\n",
       "      <td>walking through a crowd, the village is aglow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>Blank Space</td>\n",
       "      <td>Nice to meet you, where you been? I could show...</td>\n",
       "      <td>502</td>\n",
       "      <td>nice to meet you, where you been? i could show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>Style</td>\n",
       "      <td>Midnight You come and pick me up, no headlight...</td>\n",
       "      <td>371</td>\n",
       "      <td>midnight you come and pick me up, no headlight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>Out of the Woods</td>\n",
       "      <td>Looking at it now It all seems so simple We we...</td>\n",
       "      <td>652</td>\n",
       "      <td>looking at it now it all seems so simple we we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>All You Had to Do Was Stay</td>\n",
       "      <td>People like you always want back The love they...</td>\n",
       "      <td>453</td>\n",
       "      <td>people like you always want back the love they...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  album  year  track_n                 track_title  \\\n",
       "0  1989  2014        1         Welcome to New York   \n",
       "1  1989  2014        2                 Blank Space   \n",
       "2  1989  2014        3                       Style   \n",
       "3  1989  2014        4            Out of the Woods   \n",
       "4  1989  2014        5  All You Had to Do Was Stay   \n",
       "\n",
       "                                               lyric  word_count  \\\n",
       "0  Walking through a crowd, the village is aglow ...         321   \n",
       "1  Nice to meet you, where you been? I could show...         502   \n",
       "2  Midnight You come and pick me up, no headlight...         371   \n",
       "3  Looking at it now It all seems so simple We we...         652   \n",
       "4  People like you always want back The love they...         453   \n",
       "\n",
       "                                        clean_lyrics  \n",
       "0  walking through a crowd, the village is aglow ...  \n",
       "1  nice to meet you, where you been? i could show...  \n",
       "2  midnight you come and pick me up, no headlight...  \n",
       "3  looking at it now it all seems so simple we we...  \n",
       "4  people like you always want back the love they...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding  contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is a little trickier. I want to expand out all the contractions in the lyrics. \n",
    "Let's identify them first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" '45\", \" 'baby\", \" 'bout\", \" 'cause\", \" 'em\", \" 'fore\", \" 'i\", \" 'round\", \" 'til\", \" 'till\", \" 'yes\", \"ain't\", \"aren't\", \"baby's\", \"battle's\", \"beggin' \", \"bein' \", \"breakin' \", \"brother's\", \"burnin' \", \"c'mon\", \"callin' \", \"can't\", \"city's\", \"comin' \", \"cory's\", \"could've\", \"couldn't\", \"cruisin' \", \"cryin' \", \"daddy's\", \"darlin' \", \"didn't\", \"doesn't\", \"doin' \", \"don't\", \"drinkin' \", \"drivin' \", \"dyin' \", \"everybody's\", \"everything's\", \"father's\", \"gettin' \", \"gon' \", \"gravity's\", \"groovin' \", \"guessin' \", \"hadn't\", \"hand's\", \"hasn't\", \"haven't\", \"he'd\", \"he'll\", \"he's\", \"heart's\", \"here' \", \"here's\", \"holdin' \", \"how'd\", \"how's\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"isn't\", \"it'll\", \"it's\", \"jury's\", \"let's\", \"lookin' \", \"love's\", \"lovin' \", \"lyin' \", \"magic's\", \"makin' \", \"man's\", \"mom's\", \"momma's\", \"mother's\", \"movin' \", \"n' \", \"nineteen's\", \"nobody's\", \"nothin' \", \"nothing's\", \"one's\", \"parents' \", \"passenger's\", \"people's\", \"pickin' \", \"pj's\", \"reputation's\", \"ridin' \", \"runnin' \", \"sayin' \", \"she'd\", \"she'll\", \"she's\", \"should've\", \"shoulda' \", \"shouldn't\", \"sister's\", \"sittin' \", \"sixties' \", \"skippin' \", \"sneakin' \", \"someone's\", \"something's\", \"sparkin' \", \"standin' \", \"story's\", \"strangers' \", \"thankin' \", \"that'll\", \"that's\", \"there's\", \"they'll\", \"they're\", \"thing's\", \"thinkin' \", \"tomorrow's\", \"tonight's\", \"touchin' \", \"toyin' \", \"trippin' \", \"tryin' \", \"twistin' \", \"usin' \", \"wasn't\", \"water's\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"weren't\", \"what's\", \"whippin' \", \"white's\", \"who's\", \"why'd\", \"why's\", \"won't\", \"wonderin' \", \"would've\", \"wouldn't\", \"year's\", \"you' \", \"you'd\", \"you'll\", \"you're\", \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "# Finding all the contractions that need to be addressed\n",
    "contracts = []\n",
    "for i in range(len(data['clean_lyrics'])):\n",
    "    for word in data['clean_lyrics'][i].split():\n",
    "        # adds a word if it contain's an apostrophe\n",
    "        contracts.extend(re.findall(\"[\\w]+'[\\w]+\", data['clean_lyrics'][i]))\n",
    "        # adds a word if it ends with an apostrophe\n",
    "        contracts.extend(re.findall(\"[\\w]+' \", data['clean_lyrics'][i]))\n",
    "        # adds a word if it starts with an apostrophe\n",
    "        contracts.extend(re.findall(\" '+[\\w]+\", data['clean_lyrics'][i]))\n",
    "\n",
    "contracts = list(np.unique(contracts))\n",
    "print(contracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `contraction` module and expand the most common contractions. I found a few contractions that needed manual expanding, such as **_c'mon_** , _**why'd**_ and _**that'll**_ as well as changing all the shortened verbs to their full tense (example: callin becomes **calling**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" '45\", \" 'baby\", 'about', 'because', 'them', 'before', \" 'i\", 'around', 'until', 'until', \" 'yes\", 'are not', 'are not', \"baby's\", \"battle's\", 'begging', 'being', 'breaking', \"brother's\", 'burning', 'come on', 'calling', 'can not', \"city's\", 'coming', \"cory's\", 'could have', 'could not', 'cruising', 'crying', \"daddy's\", 'darling', 'did not', 'does not', 'doing', 'do not', 'drinking', 'driving', 'dying', \"everybody's\", \"everything's\", \"father's\", 'getting', 'gong', \"gravity's\", 'grooving', 'guessing', 'had not', \"hand's\", 'has not', 'have not', 'he would', 'he will', 'he is', \"heart's\", \"here' \", \"here's\", 'holding', 'how did', 'how is', 'I would', 'I will', 'I am', 'I have', 'is not', 'it will', 'it is', \"jury's\", 'let us', 'looking', \"love's\", 'loving', 'lying', \"magic's\", 'making', \"man's\", \"mom's\", \"momma's\", \"mother's\", 'moving', 'and', \"nineteen's\", \"nobody's\", 'nothing', \"nothing's\", \"one's\", \"parents' \", \"passenger's\", \"people's\", 'picking', \"pj's\", \"reputation's\", 'riding', 'running', 'saying', 'she would', 'she will', 'she is', 'should have', 'should have', 'should not', \"sister's\", 'sitting', \"sixties' \", 'skipping', 'sneaking', \"someone's\", \"something's\", 'sparking', 'standing', \"story's\", \"strangers' \", 'thanking', 'that will', 'that is', 'there is', 'they will', 'they are', \"thing's\", 'thinking', \"tomorrow's\", \"tonight's\", 'touching', 'toying', 'tripping', 'trying', 'twisting', 'using', 'was not', \"water's\", 'we would', 'we will', 'we are', 'we have', 'were not', 'what is', 'whipping', \"white's\", 'who is', 'why did', 'why is', 'will not', 'wondering', 'would have', 'would not', \"year's\", \"you' \", 'you would', 'you will', 'you are', 'you have']\n"
     ]
    }
   ],
   "source": [
    "# This creates a list with the value of the contractions when expanded\n",
    "expands = []\n",
    "forbiddens = [\" 'bout\", \" 'cause\", \" 'em\", \" 'fore\",\n",
    "              \" 'round\", \" 'til\", \" 'till\", \"c'mon\", \"why'd\", \"that'll\", \"shoulda' \"]\n",
    "for word in contracts:\n",
    "    if word == \"n' \":\n",
    "        word = \"and\"\n",
    "    if word.endswith(\"n\\' \"):\n",
    "        word = word[:-2]\n",
    "        word += \"g\"\n",
    "\n",
    "    if word == \" 'bout\":\n",
    "        expands.append(\"about\")\n",
    "\n",
    "    if word == \" 'cause\":\n",
    "        expands.append(\"because\")\n",
    "\n",
    "    if word == \" 'em\":\n",
    "        expands.append(\"them\")\n",
    "\n",
    "    if word == \" 'fore\":\n",
    "        expands.append(\"before\")\n",
    "\n",
    "    if word == \" 'round\":\n",
    "        expands.append(\"around\")\n",
    "\n",
    "    if word == \" 'til\":\n",
    "        expands.append(\"until\")\n",
    "\n",
    "    if word == \" 'till\":\n",
    "        expands.append(\"until\")\n",
    "\n",
    "    if word == \"c'mon\":\n",
    "        expands.append(\"come on\")\n",
    "\n",
    "    if word == \"why'd\":\n",
    "        expands.append(\"why did\")\n",
    "\n",
    "    if word == \"that'll\":\n",
    "        expands.append(\"that will\")\n",
    "        \n",
    "    if word == \"shoulda' \":\n",
    "        expands.append(\"should have\")\n",
    "\n",
    "    elif word not in forbiddens:\n",
    "        expands.append(contractions.fix(word))\n",
    "print(expands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One quick adjustment to the contraction values so we can identify them when tokenize is to remove the space in front of them and the space at the end of words ending with an apostrophe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in range(len(contracts)):\n",
    "    if contracts[word].startswith(\" \"):\n",
    "        contracts[word] = contracts[word][1:]\n",
    "    if contracts[word].endswith(\"n\\' \"):\n",
    "        contracts[word] = contracts[word][:-2]\n",
    "\n",
    "# This will remove the space and the apostrophe before the word\n",
    "for word in range(len(expands)):\n",
    "    if expands[word].startswith(\" \"):\n",
    "        expands[word] = expands[word][2:]\n",
    "    if expands[word].startswith(\"\\'\"):\n",
    "        expands[word] = expands[word][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'45\", \"'baby\", \"'bout\", \"'cause\", \"'em\", \"'fore\", \"'i\", \"'round\", \"'til\", \"'till\", \"'yes\", \"ain't\", \"aren't\", \"baby's\", \"battle's\", 'beggin', 'bein', 'breakin', \"brother's\", 'burnin', \"c'mon\", 'callin', \"can't\", \"city's\", 'comin', \"cory's\", \"could've\", \"couldn't\", 'cruisin', 'cryin', \"daddy's\", 'darlin', \"didn't\", \"doesn't\", 'doin', \"don't\", 'drinkin', 'drivin', 'dyin', \"everybody's\", \"everything's\", \"father's\", 'gettin', 'gon', \"gravity's\", 'groovin', 'guessin', \"hadn't\", \"hand's\", \"hasn't\", \"haven't\", \"he'd\", \"he'll\", \"he's\", \"heart's\", \"here' \", \"here's\", 'holdin', \"how'd\", \"how's\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"isn't\", \"it'll\", \"it's\", \"jury's\", \"let's\", 'lookin', \"love's\", 'lovin', 'lyin', \"magic's\", 'makin', \"man's\", \"mom's\", \"momma's\", \"mother's\", 'movin', 'n', \"nineteen's\", \"nobody's\", 'nothin', \"nothing's\", \"one's\", \"parents' \", \"passenger's\", \"people's\", 'pickin', \"pj's\", \"reputation's\", 'ridin', 'runnin', 'sayin', \"she'd\", \"she'll\", \"she's\", \"should've\", \"shoulda' \", \"shouldn't\", \"sister's\", 'sittin', \"sixties' \", 'skippin', 'sneakin', \"someone's\", \"something's\", 'sparkin', 'standin', \"story's\", \"strangers' \", 'thankin', \"that'll\", \"that's\", \"there's\", \"they'll\", \"they're\", \"thing's\", 'thinkin', \"tomorrow's\", \"tonight's\", 'touchin', 'toyin', 'trippin', 'tryin', 'twistin', 'usin', \"wasn't\", \"water's\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"weren't\", \"what's\", 'whippin', \"white's\", \"who's\", \"why'd\", \"why's\", \"won't\", 'wonderin', \"would've\", \"wouldn't\", \"year's\", \"you' \", \"you'd\", \"you'll\", \"you're\", \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "print(contracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['45', 'baby', 'about', 'because', 'them', 'before', 'i', 'around', 'until', 'until', 'yes', 'are not', 'are not', \"baby's\", \"battle's\", 'begging', 'being', 'breaking', \"brother's\", 'burning', 'come on', 'calling', 'can not', \"city's\", 'coming', \"cory's\", 'could have', 'could not', 'cruising', 'crying', \"daddy's\", 'darling', 'did not', 'does not', 'doing', 'do not', 'drinking', 'driving', 'dying', \"everybody's\", \"everything's\", \"father's\", 'getting', 'gong', \"gravity's\", 'grooving', 'guessing', 'had not', \"hand's\", 'has not', 'have not', 'he would', 'he will', 'he is', \"heart's\", \"here' \", \"here's\", 'holding', 'how did', 'how is', 'I would', 'I will', 'I am', 'I have', 'is not', 'it will', 'it is', \"jury's\", 'let us', 'looking', \"love's\", 'loving', 'lying', \"magic's\", 'making', \"man's\", \"mom's\", \"momma's\", \"mother's\", 'moving', 'and', \"nineteen's\", \"nobody's\", 'nothing', \"nothing's\", \"one's\", \"parents' \", \"passenger's\", \"people's\", 'picking', \"pj's\", \"reputation's\", 'riding', 'running', 'saying', 'she would', 'she will', 'she is', 'should have', 'should have', 'should not', \"sister's\", 'sitting', \"sixties' \", 'skipping', 'sneaking', \"someone's\", \"something's\", 'sparking', 'standing', \"story's\", \"strangers' \", 'thanking', 'that will', 'that is', 'there is', 'they will', 'they are', \"thing's\", 'thinking', \"tomorrow's\", \"tonight's\", 'touching', 'toying', 'tripping', 'trying', 'twisting', 'using', 'was not', \"water's\", 'we would', 'we will', 'we are', 'we have', 'were not', 'what is', 'whipping', \"white's\", 'who is', 'why did', 'why is', 'will not', 'wondering', 'would have', 'would not', \"year's\", \"you' \", 'you would', 'you will', 'you are', 'you have']\n"
     ]
    }
   ],
   "source": [
    "print(expands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a dictionary of the contractions to the relative expansions to use so processing is easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'45\": '45', \"'baby\": 'baby', \"'bout\": 'about', \"'cause\": 'because', \"'em\": 'them', \"'fore\": 'before', \"'i\": 'i', \"'round\": 'around', \"'til\": 'until', \"'till\": 'until', \"'yes\": 'yes', \"ain't\": 'are not', \"aren't\": 'are not', \"baby's\": \"baby's\", \"battle's\": \"battle's\", 'beggin': 'begging', 'bein': 'being', 'breakin': 'breaking', \"brother's\": \"brother's\", 'burnin': 'burning', \"c'mon\": 'come on', 'callin': 'calling', \"can't\": 'can not', \"city's\": \"city's\", 'comin': 'coming', \"cory's\": \"cory's\", \"could've\": 'could have', \"couldn't\": 'could not', 'cruisin': 'cruising', 'cryin': 'crying', \"daddy's\": \"daddy's\", 'darlin': 'darling', \"didn't\": 'did not', \"doesn't\": 'does not', 'doin': 'doing', \"don't\": 'do not', 'drinkin': 'drinking', 'drivin': 'driving', 'dyin': 'dying', \"everybody's\": \"everybody's\", \"everything's\": \"everything's\", \"father's\": \"father's\", 'gettin': 'getting', 'gon': 'gong', \"gravity's\": \"gravity's\", 'groovin': 'grooving', 'guessin': 'guessing', \"hadn't\": 'had not', \"hand's\": \"hand's\", \"hasn't\": 'has not', \"haven't\": 'have not', \"he'd\": 'he would', \"he'll\": 'he will', \"he's\": 'he is', \"heart's\": \"heart's\", \"here' \": \"here' \", \"here's\": \"here's\", 'holdin': 'holding', \"how'd\": 'how did', \"how's\": 'how is', \"i'd\": 'I would', \"i'll\": 'I will', \"i'm\": 'I am', \"i've\": 'I have', \"isn't\": 'is not', \"it'll\": 'it will', \"it's\": 'it is', \"jury's\": \"jury's\", \"let's\": 'let us', 'lookin': 'looking', \"love's\": \"love's\", 'lovin': 'loving', 'lyin': 'lying', \"magic's\": \"magic's\", 'makin': 'making', \"man's\": \"man's\", \"mom's\": \"mom's\", \"momma's\": \"momma's\", \"mother's\": \"mother's\", 'movin': 'moving', 'n': 'and', \"nineteen's\": \"nineteen's\", \"nobody's\": \"nobody's\", 'nothin': 'nothing', \"nothing's\": \"nothing's\", \"one's\": \"one's\", \"parents' \": \"parents' \", \"passenger's\": \"passenger's\", \"people's\": \"people's\", 'pickin': 'picking', \"pj's\": \"pj's\", \"reputation's\": \"reputation's\", 'ridin': 'riding', 'runnin': 'running', 'sayin': 'saying', \"she'd\": 'she would', \"she'll\": 'she will', \"she's\": 'she is', \"should've\": 'should have', \"shoulda' \": 'should have', \"shouldn't\": 'should not', \"sister's\": \"sister's\", 'sittin': 'sitting', \"sixties' \": \"sixties' \", 'skippin': 'skipping', 'sneakin': 'sneaking', \"someone's\": \"someone's\", \"something's\": \"something's\", 'sparkin': 'sparking', 'standin': 'standing', \"story's\": \"story's\", \"strangers' \": \"strangers' \", 'thankin': 'thanking', \"that'll\": 'that will', \"that's\": 'that is', \"there's\": 'there is', \"they'll\": 'they will', \"they're\": 'they are', \"thing's\": \"thing's\", 'thinkin': 'thinking', \"tomorrow's\": \"tomorrow's\", \"tonight's\": \"tonight's\", 'touchin': 'touching', 'toyin': 'toying', 'trippin': 'tripping', 'tryin': 'trying', 'twistin': 'twisting', 'usin': 'using', \"wasn't\": 'was not', \"water's\": \"water's\", \"we'd\": 'we would', \"we'll\": 'we will', \"we're\": 'we are', \"we've\": 'we have', \"weren't\": 'were not', \"what's\": 'what is', 'whippin': 'whipping', \"white's\": \"white's\", \"who's\": 'who is', \"why'd\": 'why did', \"why's\": 'why is', \"won't\": 'will not', 'wonderin': 'wondering', \"would've\": 'would have', \"wouldn't\": 'would not', \"year's\": \"year's\", \"you' \": \"you' \", \"you'd\": 'you would', \"you'll\": 'you will', \"you're\": 'you are', \"you've\": 'you have'}\n"
     ]
    }
   ],
   "source": [
    "# Creates a dictionary containing the contractions and their respective expansions\n",
    "dictionary = dict(zip(contracts, expands))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some contractions did not include an apostrophe and are more slangly used. We process these manually in the function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_contractions(string):\n",
    "    \"\"\"\n",
    "    INSERT DOCSTRING HERE\n",
    "    \"\"\"\n",
    "\n",
    "    split_string = string.split()\n",
    "    for word in range(len(split_string)):\n",
    "        if split_string[word] in dictionary:\n",
    "            split_string[word] = dictionary[split_string[word]]\n",
    "        if split_string[word]  == \"cause\":\n",
    "            split_string[word] = \"because\"\n",
    "        if split_string[word]  == \"wanna\":\n",
    "            split_string[word] = \"want to\"\n",
    "        if split_string[word]  == \"till\":\n",
    "            split_string[word] = \"until\"\n",
    "        if split_string[word]  == \"kinda\":\n",
    "            split_string[word] = \"kind of\"\n",
    "        if split_string[word]  == \"skip-skippin'\":\n",
    "            split_string[word] = \"skip\"\n",
    "        if split_string[word]  == \"trip-trippin'\":\n",
    "            split_string[word] = \"trip\"       \n",
    "        if split_string[word]  == \"whatcha\":\n",
    "            split_string[word] = \"what are you\"\n",
    "        if split_string[word]  == \"outta\":\n",
    "            split_string[word] = \"out of\" \n",
    "        if split_string[word]  == \"shoulda'\":\n",
    "            split_string[word] = \"should have\" \n",
    "        if split_string[word]  == \"cmon\":\n",
    "            split_string[word] = \"come on\" \n",
    "        if split_string[word]  == \"shoulda\":\n",
    "            split_string[word] = \"should have\" \n",
    "\n",
    "            \n",
    "        \n",
    "        if split_string[word]  in [ \"comin\", \"screamin\", \"doin\", \"flyin\", \"shakin\", \"usin\", \"pacin\"]:\n",
    "            split_string[word] = str(split_string[word] + \"g\")\n",
    "            \n",
    "        if split_string[word].endswith(\"in\\'\"):\n",
    "            split_string[word] = str(split_string[word][:-1] + \"g\")\n",
    "    \n",
    "        if split_string[word].endswith(\"in\\',\"):\n",
    "            split_string[word] = str(split_string[word][:-2] + \"g\")\n",
    "      \n",
    "        \n",
    "    return \" \".join(split_string)\n",
    "\n",
    "\n",
    "\n",
    "#[\"sparkin\",\"beggin\",\"breakin\",\"burnin\", \"callin\", \"comin\",\"cruisin\",\n",
    "#                                  \"cryin\", \"darlin\",\"doin\", \"drinkin\", \"drivin\",\"dyin\", \"gettin\", \"groovin\",\n",
    "#                                   \"guessin\", \"wonderin\", \"whippin\", \"usin\", \"tryin\", \"trippin\", \"toyin\",\n",
    "#                                  \"thinkin\", \"thankin\", \"standin\", \"sneakin\", \"touchin\", \"twistin\",\n",
    "#                                  \"skippin\", \"sittin\", \"screamin\", \"sayin\", \"shakin\", \"runnin\", \n",
    "#                                  \"ridin\", \"pickin\", \"nothin\", \"flyin\", \"holdin\", \"lookin\", \"lovin\", \"lyin\", \n",
    "#                                  \"makin\", \"movin\", \"pacin\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now amend the column for each song title and clean the lyrics more based on these contractions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_lyrics'] = data['clean_lyrics'].map(lambda s: expanding_contractions(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New contraction cleaned song lyrics example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'long were the nights when my days once revolved around you counting my footsteps praying the floor will not fall through... again my mother accused me of losing my mind but i swore i was fine you paint me a blue sky then go back and turn it to rain and i lived in your chess game but you changed the rules everyday wondering which version of you i might get on the phone, tonight well i stopped picking up and this song is to let you know why dear john, i see it all now that you are gone do not you think i was too young to be messed with the girl in the dress cried the whole way home i should have known well maybe it is me and my blind optimism to blame or maybe it is you and your sick need to give love and take it away and you will add my name to your long list of traitors who do not understand and i look back in regret how i ignored when they said \"run as fast as you can\" dear john, i see it all now that you are gone do not you think i was too young to be messed with the girl in the dress cried the whole way home dear john, i see it all now it was wrong do not you think nineteen\\'s too young to be played by your dark, twisted games when i loved you so? i should have known you are an expert at sorry and keeping the lines blurry never impressed by me acing your tests all the girls that you have run dry have tired lifeless eyes because you burned them out but i took your matches before fire could catch me so do not look now I am shining like fireworks over your sad empty town, yeah oh, oh, oh, oh, oh, oh dear john, i see it all now that you are gone do not you think i was too young to be messed with the girl in the dress cried the whole way home i see it all now that you are gone do not you think i was too young to be messed with the girl in the dress wrote you a song, you should have known you should have known do not you think i was too young you should have known'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_lyrics'][52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization and Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I explored multiple different lemmatization methods and although this method seems the most strenuous, I believe it does the best job of identifying the roots of words while still returning a full word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reproduce this method of lemmatization you will need to follow these steps of which I ammended from the article [Lemmatization Approaches with Examples in Python](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/):\n",
    "1. Install Java from [this link](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n",
    "2. On your terminal (if using a mac) run :\n",
    "\n",
    "    ```brew cask install java ```\n",
    "\n",
    "\n",
    "3. Install the python package `stanfordcorenlp` on your terminal using:\n",
    "\n",
    "    ```pip install stanfordcorenlp```\n",
    "    \n",
    "    \n",
    "4. Download Standford CoreNLP software from [this link](https://stanfordnlp.github.io/CoreNLP/index.html#download).\n",
    "5. Locate yourself to the Standford CoreNLP file through your terminal and run the following:   \n",
    "``` cd stanford-corenlp-full-2018-02-27 ```   \n",
    "\n",
    "    ```java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 30000```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution to the [Lemmatization Approaches with Examples in Python](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/) article for the function below with some alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(connection, phrase):\n",
    "    \n",
    "    \"\"\"\n",
    "    INSERT DOCSTRING HERE\n",
    "    \"\"\"\n",
    "\n",
    "    props = {'annotators': 'pos,lemma',\n",
    "             'pipelineLanguage': 'en',\n",
    "             'outputFormat': 'json'}\n",
    "\n",
    "    tokenize = connection.word_tokenize(phrase)\n",
    "\n",
    "    sents_no_punct = []\n",
    "    for token in tokenize:\n",
    "        if token not in string.punctuation:\n",
    "            if token.endswith('ness') or token.endswith('less'):\n",
    "                token = token[:-4]\n",
    "            sents_no_punct.append(token)\n",
    "        \n",
    "    sentence_no_punct = \" \".join(sents_no_punct)\n",
    "\n",
    "    parsed_string = connection.annotate(sentence_no_punct, properties=props)\n",
    "    parsed_dict = json.loads(parsed_string)\n",
    "\n",
    "    lemma_list = []\n",
    "    for item in range(len(parsed_dict['sentences'])):\n",
    "        for word in parsed_dict['sentences'][item]['tokens']:\n",
    "            for key, value in word.items():\n",
    "                if key == 'lemma':\n",
    "                    lemma_list.append(value)\n",
    "\n",
    "    lemmatized = \" \".join(lemma_list)\n",
    "    lemmatized = lemmatized.translate(\n",
    "        str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return lemmatized.lower()\n",
    "\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost', port=9000, timeout=30000)\n",
    "\n",
    "\n",
    "data['clean_lyrics'] = data['clean_lyrics'].map(lambda s: preprocess(nlp, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample after preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's something 'bout the way The street looks when it's just rained There's a glow off the pavement You walk me to the car And you know I wanna ask you to dance right there In the middle of the parking lot, yeah Oh, yeah We're driving down the road I wonder if you know I'm trying so hard not to get caught up now But you're just so cool Run your hands through your hair Absent mindedly making me want you And I don't know how it gets better than this You take my hand and drag me head first Fearless And I don't know why but with you I'd dance in a storm in my best dress Fearless So baby drive slow 'til we run out of road in this one horse town I wanna stay right here in this passenger's seat You put your eyes on me In this moment now capture it, remember it And I don't know how it gets better than this You take my hand and drag me head first Fearless And I don't know why but with you I'd dance in a storm in my best dress Fearless Well you stood there with me in the doorway My hands shake, I'm not usually this way but You pull me in and I'm a little more brave It's the first kiss, it's flawless, really something It's fearless Oh, yeah And I don't know how it gets better than this You take my hand and drag me head first Fearless And I don't know why but with you I'd dance in a storm in my best dress Fearless And I don't know how it gets better than this You take my hand and drag me head first Fearless And I don't know why but with you I'd dance in a storm in my best dress Fearless Oh oh Oh yeah\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lyric'][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there be something about the way the street look when it be just rain there be a glow off the pavement you walk i to the car and you know i want to ask you to dance right there in the middle of the parking lot yeah oh yeah we be drive down the road i wonder if you know i be try so hard not to get catch up now but you be just so cool run you hand through you hair absent mindedly make i want you and i do not know how it get better than this you take my hand and drag i head first fear and i do not know why but with you i would dance in a storm in my best dress fear so baby drive slow until we run out of road in this one horse town i want to stay right here in this passenger s seat you put you eye on i in this moment now capture it remember it and i do not know how it get better than this you take my hand and drag i head first fear and i do not know why but with you i would dance in a storm in my best dress fear well you stand there with i in the doorway my hand shake i be not usually this way but you pull i in and i be a little more brave it be the first kiss it be flaw really something it be fear oh yeah and i do not know how it get better than this you take my hand and drag i head first fear and i do not know why but with you i would dance in a storm in my best dress fear and i do not know how it get better than this you take my hand and drag i head first fear and i do not know why but with you i would dance in a storm in my best dress fear oh oh oh yeah'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_lyrics'][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look too bad! Now we can finally move onto Exploratory Data Analysis and answering the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_lyrics_tokenized'] = data['clean_lyrics'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easily done. Let's explore Taylor's lyrics in entirety. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of All Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = np.concatenate(data['clean_lyrics_tokenized'].values).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_albums_vocab_count = len(all_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all her post preprocessed lyrics, from 6 of her 7 albums, she writes 37491 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(all_lyrics, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1742 of them are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part let's me explore the common lyrics Taylor uses. The code creates a dictionary with word and the count frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "#Counter(all_lyrics).most_common(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun fact \"ooh\" is used 103 times. \"ey\" is used 72, \"na\" 68 times, \"gong\" 65 times, \"uh\" 25 times and \"mm\" 19 times. all are more than \"boy\" which is is written 17 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(all_lyrics).most_common(1834)[:-1834:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the top 5000 english US works curtesy of [wordfrequency.info](http://www.wordfrequency.info). This CSV has been imported from their site and are considered the owners of the material. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_df = pd.read_csv('word_frequency.csv')\n",
    "word_frequency_list = list(word_frequency_df['Word'])\n",
    "word_frequency_list = [k.lower() for k in word_frequency_list] # change to all lowercase\n",
    "top_1000 = word_frequency_list[0:1000]\n",
    "top_100 = word_frequency_list[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to dictionary over a counter object\n",
    "all_lyrics_dict = dict(Counter(all_lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24448\n"
     ]
    }
   ],
   "source": [
    "all_lyrics_dict = dict(Counter(all_lyrics))\n",
    "common_words = 0\n",
    "original_word = dict()\n",
    "for word in all_lyrics_dict.keys(): \n",
    "    if word in top_100:\n",
    "        common_words += all_lyrics_dict[word]\n",
    "    else: \n",
    "        original_word[word] = all_lyrics_dict[word]\n",
    "print(common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32954\n"
     ]
    }
   ],
   "source": [
    "all_lyrics_dict = dict(Counter(all_lyrics))\n",
    "common_words_1000 = 0\n",
    "original_word = dict()\n",
    "for word in all_lyrics_dict.keys(): \n",
    "    if word in top_1000:\n",
    "        common_words_1000 += all_lyrics_dict[word]\n",
    "    else: \n",
    "        original_word[word] = all_lyrics_dict[word]\n",
    "print(common_words_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35954\n"
     ]
    }
   ],
   "source": [
    "all_lyrics_dict = dict(Counter(all_lyrics))\n",
    "common_words_5000 = 0\n",
    "original_word = dict()\n",
    "for word in all_lyrics_dict.keys(): \n",
    "    if word in word_frequency_list:\n",
    "        common_words_5000 += all_lyrics_dict[word]\n",
    "    else: \n",
    "        original_word[word] = all_lyrics_dict[word]\n",
    "print(common_words_5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that 24448 are from the top 100 common english words. Her original words are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ooh', 103),\n",
       " ('ey', 72),\n",
       " ('s', 70),\n",
       " ('na', 68),\n",
       " ('gon', 65),\n",
       " ('la', 42),\n",
       " ('whoa', 34),\n",
       " ('york', 30),\n",
       " ('fake', 23),\n",
       " ('mmm', 22),\n",
       " ('starlight', 22),\n",
       " ('getaway', 22),\n",
       " ('wonderland', 21),\n",
       " ('mm', 19),\n",
       " ('darling', 18),\n",
       " ('e', 16),\n",
       " ('alright', 14),\n",
       " ('ta', 14),\n",
       " ('aah', 13),\n",
       " ('loving', 13)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(original_word.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So of the total preprocessed lyrics, 65% are from the 100 most common words and 87% are from the 1000 most frequently used english words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.81"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(common_words/all_albums_vocab_count *100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.36"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(common_words_1000/all_albums_vocab_count *100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest are oooos and ahhhhs :) jk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions:\n",
    "\n",
    "* [Lemmatization Approaches with Examples in Python](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
